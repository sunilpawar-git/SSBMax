# SSBMax Test Implementation Reference
**Knowledge Base for Bug Fixing & System Understanding**

Last Updated: December 23, 2025

---

## Table of Contents
1. [System Overview](#system-overview)
2. [Test-by-Test Implementation](#test-by-test-implementation)
3. [Unified OLQ Scoring System](#unified-olq-scoring-system)
4. [Dashboard Integration](#dashboard-integration)
5. [Data Flow Architecture](#data-flow-architecture)
6. [Troubleshooting Guide](#troubleshooting-guide)

---

## System Overview

### Architecture Pattern
- **MVVM**: ViewModel â†’ Repository â†’ Firestore
- **Navigation**: ID-based (process-death safe)
- **State Management**: StateFlow with `.update {}` pattern
- **Background Processing**: WorkManager with retry logic
- **AI Service**: Gemini Flash 1.5 via Cloud Functions

### Test Categories
- **Phase 1**: OIR, PPDT (instant + OLQ scoring)
- **Phase 2 Psychology**: TAT, WAT, SRT, SDT (OLQ scoring)
- **Phase 2 GTO**: GD, GPE, Lecturette (OLQ scoring)
- **Phase 2 Interview**: AI-powered OLQ assessment

---

## Test-by-Test Implementation

### 1. OIR (Officer Intelligence Rating)

**Type**: Multiple choice (50 questions, 30 minutes)

**User Response Flow**:
```
User selects option â†’ Answer saved in session â†’ Next question
Timer countdown (delta-based, 200ms updates)
Submit â†’ Calculate instant score
```

**Timer Implementation**:
- File: `OIRTestViewModel.kt` lines 171-215
- Pattern: Delta-based countdown using `System.currentTimeMillis()`
- Auto-submit when time expires

**Response Storage**:
```
OIRTestSession.answers: Map<String, OIRAnswer>
  â”œâ”€â”€ questionId â†’ selectedOption
  â””â”€â”€ skipped flag
```

**Scoring**: Client-side instant calculation
```kotlin
correctAnswers / totalQuestions Ã— 100 = percentageScore
Category breakdown by OIRQuestionType
Difficulty breakdown by QuestionDifficulty
```

**Firestore Storage**:
```
submissions/{submissionId}
  â”œâ”€â”€ userId
  â”œâ”€â”€ testType: "OIR"
  â”œâ”€â”€ status: "SUBMITTED_PENDING_REVIEW"
  â””â”€â”€ data:
      â””â”€â”€ testResult:
          â”œâ”€â”€ percentageScore
          â”œâ”€â”€ correctAnswers
          â”œâ”€â”€ categoryScores
          â””â”€â”€ difficultyBreakdown
```

**Result Display**: Instant (no background worker)
- Screen: `OIRTestResultScreen.kt`
- Shows: Percentage, grade, category breakdown, difficulty analysis

**Dashboard Display**: Percentage score (NOT OLQ-based)

---

### 2. PPDT (Picture Perception & Description Test)

**Type**: Story writing (30s viewing + 4min writing)

**User Response Flow**:
```
View image (30s) â†’ Write story (4min) â†’ Submit
Two-phase timer: viewing then writing
```

**Timer Implementation**:
- File: `PPDTTestViewModel.kt` lines 208-291
- Pattern: Two separate timers (viewing, writing)
- Auto-transition from viewing to writing

**Response Storage**:
```
PPDTSubmission
  â”œâ”€â”€ story: String (user's text)
  â”œâ”€â”€ charactersCount: Int
  â”œâ”€â”€ viewingTimeTakenSeconds
  â””â”€â”€ writingTimeTakenMinutes
```

**Firestore Storage**:
```
submissions/{submissionId}
  â”œâ”€â”€ userId, testType: "PPDT"
  â”œâ”€â”€ status: "SUBMITTED_PENDING_REVIEW"
  â””â”€â”€ data:
      â”œâ”€â”€ story
      â”œâ”€â”€ analysisStatus: "PENDING_ANALYSIS"
      â””â”€â”€ olqResult: null (filled by worker)

ppdt_results/{submissionId}  â† Written by worker
  â”œâ”€â”€ userId
  â”œâ”€â”€ olqScores: Map<OLQ, OLQScore>
  â”œâ”€â”€ overallScore
  â”œâ”€â”€ strengths, weaknesses, recommendations
  â””â”€â”€ analyzedAt
```

**Background Worker**: `PPDTAnalysisWorker.kt`
```
1. Fetch submission from Firestore
2. Generate prompt: PsychologyTestPrompts.generatePPDTAnalysisPrompt()
3. Call Gemini AI: aiService.analyzePPDTResponse()
4. Parse JSON response â†’ OLQAnalysisResult
5. Write to ppdt_results/{submissionId}
6. Update submission status â†’ COMPLETED
7. Send push notification
```

**Gemini Prompt Structure**:
- Input: Story text, character count, completion time
- Instructions: Analyze for all 15 OLQs (1-10 scale, lower = better)
- Output: JSON with olqScores, overallScore, strengths, weaknesses

**Result Display**:
- Screen: `PPDTSubmissionResultScreen.kt`
- Fetches from: `ppdt_results/{submissionId}` via ViewModel
- Shows: OLQ breakdown, overall rating, strengths/weaknesses

---

### 3. TAT (Thematic Apperception Test)

**Type**: Story writing (12 images, 4min each)

**User Response Flow**:
```
View image â†’ Write story (4min) â†’ Next image
Repeat 12 times â†’ Submit all
```

**Timer Implementation**:
- File: `TATTestViewModel.kt` lines 305-359
- Pattern: Per-image countdown (240 seconds each)
- Auto-advance when time expires

**Response Storage**:
```
TATSubmission
  â””â”€â”€ stories: List<TATStory>
      â”œâ”€â”€ imageUrl
      â”œâ”€â”€ storyText
      â”œâ”€â”€ charCount
      â””â”€â”€ timeTakenSeconds
```

**Firestore Storage**:
```
submissions/{submissionId}
  â”œâ”€â”€ testType: "TAT"
  â””â”€â”€ data:
      â”œâ”€â”€ stories: [12 stories]
      â””â”€â”€ analysisStatus: "PENDING_ANALYSIS"

psych_results/{submissionId}  â† Unified collection
  â”œâ”€â”€ userId
  â”œâ”€â”€ testType: "TAT"
  â”œâ”€â”€ olqScores: Map<OLQ, OLQScore>
  â””â”€â”€ overallScore
```

**Background Worker**: `TATAnalysisWorker.kt`
```
1. Fetch submission with 12 stories
2. Generate prompt with all stories
3. Gemini analyzes patterns across stories
4. Write to psych_results/{submissionId}
5. Update submission â†’ COMPLETED
6. Send notification
```

**Gemini Analysis Focus**:
- Hero characteristics (positive, proactive)
- Problem-solving approaches
- Outcome positivity
- Leadership indicators
- OLQ pattern detection across 12 stories

**Result Display**: `TATSubmissionResultScreen.kt`

---

### 4. WAT (Word Association Test)

**Type**: 60 words, 15 seconds each

**User Response Flow**:
```
Word displayed â†’ Type response (15s) â†’ Auto-advance
Repeat 60 times â†’ Auto-submit
```

**Timer Implementation**:
- File: `WATTestViewModel.kt` lines 223-265
- Pattern: Per-word countdown (15 seconds)
- Auto-submit response when time expires
- No manual "Next" button

**Response Storage**:
```
WATSubmission
  â””â”€â”€ responses: List<WATWordResponse>
      â”œâ”€â”€ word: "LEADER"
      â”œâ”€â”€ response: "Takes charge"
      â”œâ”€â”€ timeTakenSeconds: 8
      â””â”€â”€ isSkipped: false
```

**Firestore Storage**:
```
submissions/{submissionId}
  â”œâ”€â”€ testType: "WAT"
  â””â”€â”€ data:
      â””â”€â”€ responses: [60 responses]

psych_results/{submissionId}
  â”œâ”€â”€ testType: "WAT"
  â””â”€â”€ olqScores: Map<OLQ, OLQScore>
```

**Background Worker**: `WATAnalysisWorker.kt`

**Gemini Analysis Focus**:
- Response speed (faster = better)
- Positive vs negative associations
- Leadership/action-oriented words
- Avoid: Personal statements, facts, idioms
- Prefer: Observational statements

**Result Display**: `WATSubmissionResultScreen.kt`

---

### 5. SRT (Situation Reaction Test)

**Type**: 60 situations, 30 seconds each

**User Response Flow**:
```
Situation displayed â†’ Write reaction (30s) â†’ Next
Repeat 60 times â†’ Submit
```

**Timer Implementation**:
- File: `SRTTestViewModel.kt` lines 258-301
- Pattern: Per-situation countdown (30 seconds)
- Manual "Next" button (no auto-advance)

**Response Storage**:
```
SRTSubmission
  â””â”€â”€ responses: List<SRTSituationResponse>
      â”œâ”€â”€ situation: "Fire in building"
      â”œâ”€â”€ reaction: "Alert others, call 911"
      â”œâ”€â”€ timeTakenSeconds: 20
      â””â”€â”€ charCount: 25
```

**Firestore Storage**:
```
submissions/{submissionId}
  â”œâ”€â”€ testType: "SRT"
  â””â”€â”€ data: responses

psych_results/{submissionId}
  â”œâ”€â”€ testType: "SRT"
  â””â”€â”€ olqScores
```

**Background Worker**: `SRTAnalysisWorker.kt`

**Gemini Analysis Focus**:
- Proactive vs reactive responses
- Helping others mentioned
- Leadership actions
- Practical solutions
- Speed of decision-making

**Result Display**: `SRTSubmissionResultScreen.kt`

---

### 6. SDT (Self Description Test)

**Type**: 4 questions, 15 minutes total

**User Response Flow**:
```
Question 1: Parents' opinion â†’ Write
Question 2: Teachers' opinion â†’ Write
Question 3: Friends' opinion â†’ Write
Question 4: Own opinion â†’ Write
Shared 15-minute timer
```

**Timer Implementation**:
- File: `SDTTestViewModel.kt` lines 300-343
- Pattern: Shared timer (900 seconds total)
- User can switch between questions freely

**Response Storage**:
```
SDTSubmission
  â””â”€â”€ responses: List<SDTQuestionResponse>
      â”œâ”€â”€ question: "How parents see you"
      â”œâ”€â”€ answer: (user text)
      â”œâ”€â”€ charCount
      â””â”€â”€ timeTakenSeconds
```

**Firestore Storage**:
```
submissions/{submissionId}
  â”œâ”€â”€ testType: "SD"
  â””â”€â”€ data: responses

psych_results/{submissionId}
  â”œâ”€â”€ testType: "SD"
  â””â”€â”€ olqScores
```

**Background Worker**: `SDTAnalysisWorker.kt`
- Enqueued: Line 264 in `SDTTestViewModel.kt`
- Method: `enqueueSDTAnalysisWorker()` (lines 350-365)

**Gemini Analysis Focus**:
- Self-awareness consistency
- Honesty in self-perception
- Goal orientation
- Maturity indicators
- Social relationships

**Result Display**: `SDTSubmissionResultScreen.kt`

---

### 7. GD (Group Discussion)

**Type**: Topic-based discussion, 20 minutes

**User Response Flow**:
```
Topic displayed â†’ Type response (20min) â†’ Submit
White noise audio during test (optional)
```

**Timer Implementation**:
- File: `GDTestViewModel.kt`
- Pattern: Single 20-minute countdown

**Response Storage**:
```
GTOSubmission.GDSubmission
  â”œâ”€â”€ topic: "Leadership in military"
  â”œâ”€â”€ response: (user text)
  â”œâ”€â”€ charCount
  â””â”€â”€ timeSpent
```

**Firestore Storage**:
```
submissions/{submissionId}
  â”œâ”€â”€ testType: "GTO_GD"
  â””â”€â”€ data: { topic, response, timeSpent }

gto_results/{submissionId}  â† Separate collection
  â”œâ”€â”€ userId
  â”œâ”€â”€ testType: "GROUP_DISCUSSION"
  â”œâ”€â”€ olqScores: Map<OLQ, OLQScore>
  â””â”€â”€ overallScore
```

**Background Worker**: `GTOAnalysisWorker.kt`
```
1. Fetch submission
2. Generate prompt: GTOTestPrompts (not PsychologyTestPrompts)
3. Gemini analysis
4. Batch write:
   - gto_results/{submissionId}
   - Update submission status â†’ COMPLETED
5. Send notification
```

**Gemini Analysis Focus**:
- Communication clarity
- Logical argumentation
- Team orientation
- Leadership indicators

**Result Display**: `GDSubmissionResultScreen.kt`

---

### 8. GPE (Group Planning Exercise)

**Type**: Tactical scenario planning, 30 minutes

**User Response Flow**:
```
View image + scenario (60s) â†’ Write plan (29min) â†’ Submit
```

**Timer Implementation**:
- Two-phase: 60s viewing + 1740s planning

**Response Storage**:
```
GTOSubmission.GPESubmission
  â”œâ”€â”€ imageUrl
  â”œâ”€â”€ scenario
  â”œâ”€â”€ solution (optional)
  â”œâ”€â”€ plan: (user text)
  â””â”€â”€ characterCount
```

**Firestore Storage**:
```
submissions/{submissionId}
  â”œâ”€â”€ testType: "GTO_GPE"
  â””â”€â”€ data: scenario + plan

gto_results/{submissionId}
  â”œâ”€â”€ testType: "GROUP_PLANNING_EXERCISE"
  â””â”€â”€ olqScores
```

**Background Worker**: `GTOAnalysisWorker.kt` (same as GD)

**Gemini Analysis Focus**:
- Tactical planning
- Resource utilization
- Risk assessment
- Organizing ability
- Decision-making

**Result Display**: `GPESubmissionResultScreen.kt`

---

### 9. Lecturette

**Type**: 3-minute speech, 4 topic choices

**User Response Flow**:
```
4 topics shown â†’ Select 1 â†’ Prepare (3min) â†’ Record/Type speech â†’ Submit
```

**Timer Implementation**:
- 3-minute countdown for speech delivery

**Response Storage**:
```
GTOSubmission.LecturetteSubmission
  â”œâ”€â”€ topicChoices: [4 topics]
  â”œâ”€â”€ selectedTopic
  â”œâ”€â”€ speechTranscript: (text)
  â””â”€â”€ charCount
```

**Firestore Storage**:
```
submissions/{submissionId}
  â”œâ”€â”€ testType: "GTO_LECTURETTE"
  â””â”€â”€ data: topic + transcript

gto_results/{submissionId}
  â”œâ”€â”€ testType: "LECTURETTE"
  â””â”€â”€ olqScores
```

**Background Worker**: `GTOAnalysisWorker.kt`

**Gemini Analysis Focus**:
- Communication skills
- Knowledge depth
- Confidence indicators
- Power of expression
- Organizing thoughts

**Result Display**: `LecturetteResultScreen.kt`

---

### 10. Interview

**Type**: Multi-question AI interview, ~10-15 minutes

**User Response Flow**:
```
Question displayed â†’ Type/Speak response â†’ Submit
AI generates follow-up â†’ Repeat
All responses saved â†’ Submit interview
```

**Timer Implementation**:
- Per-question thinking time tracking
- No hard time limit (user-paced)

**Response Storage**:
```
InterviewResponse (per question)
  â”œâ”€â”€ questionId
  â”œâ”€â”€ questionText
  â”œâ”€â”€ responseText
  â”œâ”€â”€ responseMode: TEXT | VOICE
  â”œâ”€â”€ thinkingTimeSec
  â””â”€â”€ olqScores: {} (empty until analyzed)

InterviewSession
  â”œâ”€â”€ sessionId
  â”œâ”€â”€ questionIds: [5-15 questions]
  â””â”€â”€ status: PENDING_ANALYSIS
```

**Firestore Storage**:
```
interview_sessions/{sessionId}
  â”œâ”€â”€ userId
  â”œâ”€â”€ mode: MOCK | PRACTICE
  â”œâ”€â”€ questionIds
  â””â”€â”€ status: "PENDING_ANALYSIS"

interview_responses/{responseId}  â† One per question
  â”œâ”€â”€ sessionId
  â”œâ”€â”€ questionId
  â”œâ”€â”€ responseText
  â””â”€â”€ olqScores: {} (filled by worker)

interview_results/{sessionId}  â† Final aggregation
  â”œâ”€â”€ userId
  â”œâ”€â”€ overallOLQScores: Map<OLQ, OLQScore>
  â”œâ”€â”€ responses: [all responses with scores]
  â””â”€â”€ completedAt
```

**Background Worker**: `InterviewAnalysisWorker.kt`
```
1. Fetch all responses for session
2. For each response:
   - Generate prompt with question context
   - Gemini analyzes for 3-5 target OLQs
   - Parse JSON â†’ update response.olqScores
3. Aggregate all OLQ scores
4. Create InterviewResult
5. Update session â†’ COMPLETED
6. Send notification
```

**Worker Triggering**:
- File: `InterviewSessionViewModel.kt` lines 476-521
- Method: `enqueueAnalysisWorker()` (lines 502-521)

**Gemini Analysis**:
- Per-response analysis (not batch)
- Focuses on 3-5 OLQs per question
- Looks for: Leadership, decision-making, reasoning, responsibility
- Uses: `SSBInterviewPrompts.kt` (not PsychologyTestPrompts)

**Result Display**: `InterviewResultScreen.kt`
- Shows: Overall OLQ averages + per-question breakdown

---

## Unified OLQ Scoring System

### Core Components

**OLQ Enum** (`core/domain/model/interview/OLQ.kt`):
```kotlin
15 OLQs grouped in 4 categories:
â”œâ”€â”€ INTELLECTUAL (4): Effective Intelligence, Reasoning, Organizing, Expression
â”œâ”€â”€ SOCIAL (3): Social Adjustment, Cooperation, Responsibility
â”œâ”€â”€ DYNAMIC (5): Initiative, Confidence, Speed of Decision, Influence, Liveliness
â””â”€â”€ CHARACTER (3): Determination, Courage, Stamina
```

**OLQ Score** (1-10 scale, **LOWER = BETTER**):
```
1-3: Exceptional (rare, outstanding)
4:   Excellent (top tier)
5:   Very Good (best common score)
6:   Good (above average)
7:   Average (typical)
8:   Below Average (needs improvement)
9-10: Poor (major deficiency)
```

**OLQAnalysisResult** (`core/domain/model/scoring/UnifiedOLQResult.kt`):
```kotlin
data class OLQAnalysisResult(
    submissionId: String,
    testType: TestType,
    olqScores: Map<OLQ, OLQScore>,  // All 15 OLQs
    overallScore: Float,             // Average of all scores
    overallRating: String,           // "Exceptional", "Good", etc.
    strengths: List<String>,         // Top 3 OLQs (lowest scores)
    weaknesses: List<String>,        // Bottom 3 OLQs (highest scores)
    recommendations: List<String>,
    analyzedAt: Long,
    aiConfidence: Int                // 0-100
)
```

### Analysis Flow

**1. Submission â†’ Worker Enqueue**
```kotlin
// Pattern used by all tests:
viewModelScope.launch {
    val submissionId = submitTest().getOrThrow()
    enqueueAnalysisWorker(submissionId)
    getOLQDashboard.invalidateCache(userId)
}
```

**2. Worker Execution**
```kotlin
// Pattern: PPDTAnalysisWorker.kt (reference implementation)
override suspend fun doWork(): Result {
    val submissionId = inputData.getString(KEY_SUBMISSION_ID)
    
    // 1. Fetch submission
    val submission = submissionRepository.getSubmission(submissionId)
    
    // 2. Verify PENDING_ANALYSIS
    if (submission.analysisStatus != PENDING_ANALYSIS) return
    
    // 3. Update to ANALYZING
    submissionRepository.updateStatus(submissionId, ANALYZING)
    
    // 4. Generate prompt
    val prompt = PsychologyTestPrompts.generate...(submission)
    
    // 5. Call Gemini with retry logic
    val olqScores = analyzeWithRetry(prompt, maxRetries = 3)
    
    // 6. Create OLQAnalysisResult
    val result = OLQAnalysisResult(
        submissionId = submissionId,
        testType = TestType.XXX,
        olqScores = olqScores,  // All 15 OLQs
        overallScore = olqScores.values.map { it.score }.average(),
        // ... compute strengths/weaknesses
    )
    
    // 7. Write to results collection
    submissionRepository.updateOLQResult(submissionId, result)
    
    // 8. Update submission â†’ COMPLETED
    submissionRepository.updateStatus(submissionId, COMPLETED)
    
    // 9. Send notification
    notificationHelper.showResultsReady(submissionId)
    
    return Result.success()
}
```

**3. Retry Logic** (all workers):
```kotlin
private suspend fun analyzeWithRetry(prompt: String): Map<OLQ, OLQScore>? {
    repeat(3) { attempt ->
        try {
            val result = aiService.analyze(prompt)
            if (result.olqScores.size >= 14) {  // Accept 14-15 OLQs
                return fillMissingOLQs(result.olqScores)
            }
        } catch (e: Exception) {
            delay(2000L * (attempt + 1))  // Exponential backoff
        }
    }
    return null  // Failed after 3 retries
}

private fun fillMissingOLQs(scores: Map<OLQ, OLQScore>): Map<OLQ, OLQScore> {
    return OLQ.entries.associateWith { olq ->
        scores[olq] ?: OLQScore(
            score = 6,  // Neutral default
            confidence = 30,
            reasoning = "AI did not assess - neutral assigned"
        )
    }
}
```

### Gemini Prompt Structure

**Common Pattern** (all psychology tests):
```
You are an SSB PSYCHOLOGIST analyzing [TEST_NAME].

CANDIDATE RESPONSES:
[User's test responses]

OLQ SCORING REFERENCE:
[15 OLQ definitions with examples]

SCORING SCALE (SSB Convention - LOWER IS BETTER):
1-2 = Exceptional
3   = Excellent
4   = Very Good
5   = Good
6   = Average
7   = Below Average
8-10 = Poor

DISTRIBUTION GUIDELINE:
- Most candidates: 5-7 (70%)
- Exceptional (1-3) and Poor (8-10): rare (15% each)

YOUR TASK:
Analyze responses and provide OLQ assessment.

OUTPUT FORMAT (Return ONLY valid JSON):
{
  "olqScores": {
    "EFFECTIVE_INTELLIGENCE": {"score": 5, "confidence": 80, "reasoning": "..."},
    "REASONING_ABILITY": {"score": 6, "confidence": 75, "reasoning": "..."},
    ... (all 15 OLQs)
  },
  "overallScore": 5.5,
  "overallRating": "Good",
  "strengths": ["Leadership shown", "Proactive responses"],
  "weaknesses": ["Limited self-awareness", "Reactive patterns"],
  "recommendations": ["Focus on X", "Improve Y"],
  "aiConfidence": 82
}

CRITICAL: Return ONLY JSON. No markdown, no explanations.
```

**Test-Specific Focus**:
- **TAT**: Story heroes, positive outcomes, problem-solving patterns
- **WAT**: Response speed, positive associations, action-orientation
- **SRT**: Proactive responses, helping others, leadership actions
- **SDT**: Self-awareness, goal orientation, maturity
- **GTO**: Team orientation, planning ability, communication
- **Interview**: Specific OLQs per question (3-5 OLQs each)

### Result Storage Patterns

**Psychology Tests** (TAT, WAT, SRT, SDT):
```
psych_results/{submissionId}
  â”œâ”€â”€ userId (CRITICAL for security rules)
  â”œâ”€â”€ submissionId
  â”œâ”€â”€ testType: "TAT" | "WAT" | "SRT" | "SD"
  â”œâ”€â”€ olqScores: {
  â”‚     "EFFECTIVE_INTELLIGENCE": {score: 5, confidence: 80, reasoning: "..."},
  â”‚     ... (all 15)
  â”‚   }
  â”œâ”€â”€ overallScore: 5.5
  â”œâ”€â”€ overallRating: "Good"
  â”œâ”€â”€ strengths: ["..."]
  â”œâ”€â”€ weaknesses: ["..."]
  â”œâ”€â”€ recommendations: ["..."]
  â””â”€â”€ analyzedAt: timestamp
```

**GTO Tests** (GD, GPE, Lecturette):
```
gto_results/{submissionId}
  â”œâ”€â”€ userId
  â”œâ”€â”€ submissionId
  â”œâ”€â”€ testType: "GROUP_DISCUSSION" | "GROUP_PLANNING_EXERCISE" | "LECTURETTE"
  â”œâ”€â”€ olqScores: Map<OLQ, OLQScore>
  â””â”€â”€ ... (same as psych_results)
```

**PPDT**:
```
ppdt_results/{submissionId}
  â”œâ”€â”€ userId
  â”œâ”€â”€ submissionId
  â”œâ”€â”€ testType: "PPDT"
  â””â”€â”€ ... (same structure)
```

**Interview**:
```
interview_results/{sessionId}
  â”œâ”€â”€ userId
  â”œâ”€â”€ sessionId (not submissionId)
  â”œâ”€â”€ overallOLQScores: Map<OLQ, OLQScore>  â† Aggregated
  â”œâ”€â”€ responses: [
  â”‚     {questionId, responseText, olqScores: {...}},
  â”‚     ... (per-question OLQ scores)
  â”‚   ]
  â””â”€â”€ completedAt
```

---

## Dashboard Integration

### Data Fetching Flow

**Use Case**: `GetOLQDashboardUseCase.kt`

**Execution**:
```kotlin
suspend operator fun invoke(userId: String, forceRefresh: Boolean = false) {
    // 1. Check cache (5-minute TTL)
    val cached = cache[userId]
    if (!forceRefresh && cached != null && !isExpired(cached)) {
        return cached.data
    }
    
    // 2. Fetch all test results in parallel
    val oirResult = getLatestOIRSubmission(userId).getOrNull()?.testResult
    val ppdtResult = getLatestPPDTSubmission(userId).getOrNull()
    val ppdtOLQ = getPPDTResult(ppdtResult?.id).getOrNull()
    
    val tatResult = getTATResult(getLatestTATSubmission(userId).id).getOrNull()
    val watResult = getWATResult(getLatestWATSubmission(userId).id).getOrNull()
    val srtResult = getSRTResult(getLatestSRTSubmission(userId).id).getOrNull()
    val sdResult = getSDTResult(getLatestSDTSubmission(userId).id).getOrNull()
    
    val gtoResults = GTOTestType.entries.associateWith { type ->
        gtoRepository.getUserResults(userId, type).first().firstOrNull()
    }
    
    val interviewResult = interviewRepository.getUserResults(userId).first().firstOrNull()
    
    // 3. Build dashboard data
    val dashboard = OLQDashboardData(
        userId = userId,
        phase1Results = Phase1Results(oirResult, ppdtResult, ppdtOLQ),
        phase2Results = Phase2Results(
            tatResult, watResult, srtResult, sdResult,
            gtoResults, interviewResult
        )
    )
    
    // 4. Compute aggregations ONCE (not in UI)
    val averageOLQScores = computeAverageOLQScores(dashboard)
    val topOLQs = averageOLQScores.sortedBy { it.value }.take(3)
    val improvementOLQs = averageOLQScores.sortedByDescending { it.value }.take(3)
    val overallAverage = computeOverallAverage(dashboard)
    
    // 5. Return processed data
    return ProcessedDashboardData(
        dashboard, averageOLQScores, topOLQs, improvementOLQs, overallAverage
    )
}
```

**Cache Invalidation**:
```kotlin
// Called after every test submission
getOLQDashboard.invalidateCache(userId)

// Locations:
- OIRTestViewModel.kt line 366
- PPDTTestViewModel.kt (similar)
- TATTestViewModel.kt (similar)
- WATTestViewModel.kt line 366
- SRTTestViewModel.kt line 410
- SDTTestViewModel.kt line 274
- GTOTestViewModels (all)
- InterviewViewModel (similar)
```

### OLQ Aggregation Logic

**Average OLQ Scores** (across all tests):
```kotlin
private fun computeAverageOLQScores(dashboard: OLQDashboardData): Map<OLQ, Float> {
    val olqScoresMap = mutableMapOf<OLQ, Float>()
    
    OLQ.entries.forEach { olq ->
        val scores = mutableListOf<Float>()
        
        // Phase 1: PPDT only (OIR not OLQ-based)
        dashboard.phase1Results.ppdtOLQResult?.olqScores?.get(olq)?.score
            ?.let { scores.add(it.toFloat()) }
        
        // Phase 2: All psychology tests
        dashboard.phase2Results.tatResult?.olqScores?.get(olq)?.score
            ?.let { scores.add(it.toFloat()) }
        dashboard.phase2Results.watResult?.olqScores?.get(olq)?.score
            ?.let { scores.add(it.toFloat()) }
        dashboard.phase2Results.srtResult?.olqScores?.get(olq)?.score
            ?.let { scores.add(it.toFloat()) }
        dashboard.phase2Results.sdResult?.olqScores?.get(olq)?.score
            ?.let { scores.add(it.toFloat()) }
        
        // GTO Tests (all 8 types)
        dashboard.phase2Results.gtoResults.values.forEach { gtoResult ->
            gtoResult.olqScores[olq]?.score?.let { scores.add(it.toFloat()) }
        }
        
        // Interview
        dashboard.phase2Results.interviewResult?.overallOLQScores?.get(olq)?.score
            ?.let { scores.add(it.toFloat()) }
        
        if (scores.isNotEmpty()) {
            olqScoresMap[olq] = scores.average().toFloat()
        }
    }
    
    return olqScoresMap
}
```

**Overall Average** (single score across all tests):
```kotlin
private fun computeOverallAverage(dashboard: OLQDashboardData): Float? {
    val allScores = mutableListOf<Float>()
    
    dashboard.phase1Results.ppdtOLQResult?.overallScore?.let { allScores.add(it) }
    dashboard.phase2Results.tatResult?.overallScore?.let { allScores.add(it) }
    dashboard.phase2Results.watResult?.overallScore?.let { allScores.add(it) }
    dashboard.phase2Results.srtResult?.overallScore?.let { allScores.add(it) }
    dashboard.phase2Results.sdResult?.overallScore?.let { allScores.add(it) }
    
    dashboard.phase2Results.gtoResults.values.forEach { 
        allScores.add(it.overallScore) 
    }
    
    dashboard.phase2Results.interviewResult?.getAverageOLQScore()
        ?.let { allScores.add(it) }
    
    return if (allScores.isNotEmpty()) allScores.average().toFloat() else null
}
```

### UI Display

**Dashboard Card**: `OLQDashboardCard.kt`

**Layout**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Your SSB Progress    [8/10 Tests]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PHASE 1    â”‚     PHASE 2           â”‚
â”‚             â”‚                       â”‚
â”‚  OIR: 85.0  â”‚  Psychology           â”‚
â”‚  PPDT: 5.5  â”‚   TAT: 5.2            â”‚
â”‚             â”‚   WAT: 5.8            â”‚
â”‚             â”‚   SRT: 5.4            â”‚
â”‚             â”‚   Self Desc: 6.1      â”‚
â”‚             â”‚                       â”‚
â”‚             â”‚  GTO                  â”‚
â”‚             â”‚   GD: 5.5             â”‚
â”‚             â”‚   GPE: 5.7            â”‚
â”‚             â”‚   Lecturette: 6.0     â”‚
â”‚             â”‚                       â”‚
â”‚             â”‚  Interview            â”‚
â”‚             â”‚   Interview: 5.6      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Overall Average: 5.6                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŒŸ Your Strengths                   â”‚
â”‚  â€¢ Effective Intelligence (4.8)     â”‚
â”‚  â€¢ Initiative (5.0)                 â”‚
â”‚  â€¢ Reasoning Ability (5.2)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“ˆ Focus Areas                      â”‚
â”‚  â€¢ Courage (7.2)                    â”‚
â”‚  â€¢ Stamina (6.8)                    â”‚
â”‚  â€¢ Determination (6.5)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Color Coding**:
```
Score â‰¤ 5.0: Green (Good)
Score 5.1-7.0: Amber (Average)
Score > 7.0: Red (Needs Improvement)
```

**Clickable Navigation**:
```kotlin
TestScoreChip(
    testName = "TAT",
    score = dashboard.tatResult?.overallScore,
    onClick = { onNavigateToResult(TestType.TAT, submissionId) }
)
```

---

## Data Flow Architecture

### Complete Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Completes  â”‚
â”‚      Test        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ViewModel.submitTest()           â”‚
â”‚ â”œâ”€ Create submission             â”‚
â”‚ â”œâ”€ Save to Firestore             â”‚
â”‚ â”œâ”€ Enqueue WorkManager job       â”‚
â”‚ â”œâ”€ Invalidate dashboard cache    â”‚
â”‚ â””â”€ Navigate to result/pending    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WorkManager Background Worker    â”‚
â”‚ â”œâ”€ Fetch submission from Firestoreâ”‚
â”‚ â”œâ”€ Generate AI prompt           â”‚
â”‚ â”œâ”€ Call Gemini AI (with retry)  â”‚
â”‚ â”œâ”€ Parse JSON â†’ OLQAnalysisResultâ”‚
â”‚ â”œâ”€ Write to results collection   â”‚
â”‚ â”œâ”€ Update submission â†’ COMPLETEDâ”‚
â”‚ â””â”€ Send push notification        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Taps Notification           â”‚
â”‚ OR Navigates to Home Screen      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GetOLQDashboardUseCase           â”‚
â”‚ â”œâ”€ Check cache (5min TTL)        â”‚
â”‚ â”œâ”€ Fetch all test results        â”‚
â”‚ â”œâ”€ Compute aggregations           â”‚
â”‚ â””â”€ Return ProcessedDashboardData â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OLQDashboardCard                 â”‚
â”‚ â”œâ”€ Display all scores            â”‚
â”‚ â”œâ”€ Show strengths/weaknesses     â”‚
â”‚ â””â”€ Navigate to individual resultsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Firestore Collections

```
submissions/{submissionId}
  â”œâ”€â”€ Used by: All tests
  â”œâ”€â”€ Contains: Raw test responses + metadata
  â”œâ”€â”€ Status field: "PENDING_ANALYSIS" â†’ "ANALYZING" â†’ "COMPLETED"
  â””â”€â”€ Security: User can read/write own submissions

psych_results/{submissionId}
  â”œâ”€â”€ Used by: TAT, WAT, SRT, SDT
  â”œâ”€â”€ Contains: OLQAnalysisResult
  â”œâ”€â”€ Written by: Workers (not client)
  â””â”€â”€ Security: User can read/write own results (userId field required)

gto_results/{submissionId}
  â”œâ”€â”€ Used by: GD, GPE, Lecturette, PGT, HGT, GOR, IO, CT
  â”œâ”€â”€ Contains: OLQAnalysisResult
  â””â”€â”€ Security: Same as psych_results

ppdt_results/{submissionId}
  â”œâ”€â”€ Used by: PPDT only
  â”œâ”€â”€ Contains: OLQAnalysisResult
  â””â”€â”€ Security: Same as psych_results

interview_sessions/{sessionId}
  â”œâ”€â”€ Used by: Interview
  â”œâ”€â”€ Contains: Session metadata + question IDs
  â””â”€â”€ Status: "IN_PROGRESS" â†’ "PENDING_ANALYSIS" â†’ "COMPLETED"

interview_responses/{responseId}
  â”œâ”€â”€ Used by: Interview (per question)
  â”œâ”€â”€ Contains: Single question response + olqScores
  â””â”€â”€ Updated by: InterviewAnalysisWorker

interview_results/{sessionId}
  â”œâ”€â”€ Used by: Interview
  â”œâ”€â”€ Contains: Aggregated OLQ scores + all responses
  â””â”€â”€ Created by: InterviewAnalysisWorker
```

### Security Rules Pattern

```javascript
// Firestore rules (firestore.rules)

// Submissions - users can read/write own
match /submissions/{submissionId} {
  allow read: if resource.data.userId == request.auth.uid;
  allow create: if request.resource.data.userId == request.auth.uid;
  allow update: if resource.data.userId == request.auth.uid;
}

// Results - users can read/write own (userId required)
match /psych_results/{resultId} {
  allow read, write: if (resource == null || 
                          resource.data.userId == request.auth.uid || 
                          request.resource.data.userId == request.auth.uid);
}

match /gto_results/{resultId} {
  allow read, write: if (resource == null || 
                          resource.data.userId == request.auth.uid || 
                          request.resource.data.userId == request.auth.uid);
}

match /ppdt_results/{resultId} {
  allow read, write: if (resource == null || 
                          resource.data.userId == request.auth.uid || 
                          request.resource.data.userId == request.auth.uid);
}
```

---

## Troubleshooting Guide

### Common Issues & Solutions

**Issue**: OLQ scores not showing on dashboard
```
Check:
1. Worker completed? â†’ Check Firestore: results collection exists
2. Cache stale? â†’ Pull-to-refresh or wait 5 minutes
3. UserId in results? â†’ Firestore rules require userId field
4. Correct collection? â†’ TAT/WAT/SRT/SDT use psych_results, GTO uses gto_results
```

**Issue**: Worker not triggering
```
Check:
1. WorkManager enqueued? â†’ Look for enqueue...Worker() call in ViewModel
2. Network constraint? â†’ Ensure device has internet
3. Submission saved? â†’ Check Firestore submissions collection
4. Status correct? â†’ Should be PENDING_ANALYSIS after submission
```

**Issue**: AI analysis stuck in "ANALYZING"
```
Check:
1. Gemini API quota â†’ Firebase Functions logs
2. JSON parse error â†’ Worker logs (adb logcat | grep "Worker")
3. Retry exhausted â†’ Check worker retry count (max 3)
4. Network timeout â†’ Increase timeout in AIService
```

**Issue**: Dashboard shows "â€”" for test
```
Check:
1. Test completed? â†’ Check submissions collection
2. Analysis complete? â†’ Check results collection
3. OLQ result fetched? â†’ GetOLQDashboardUseCase logs
4. Dashboard cache? â†’ Invalidated after submission?
```

**Issue**: Timer not working correctly
```
Check:
1. Delta-based? â†’ Should use System.currentTimeMillis() delta
2. ViewModelScope? â†’ Timer job in viewModelScope (auto-cancels)
3. State updates? â†’ Use .update {} pattern
4. Config change? â†’ Timer should survive rotation (StateFlow)
```

### Debug Log Patterns

**Test Submission**:
```
adb logcat | grep "ViewModel"
âœ… Submission successful! ID: abc123
ğŸ“ Enqueueing ...AnalysisWorker...
âœ… ...AnalysisWorker enqueued successfully
ğŸ“ Recording test usage for subscription...
âœ… Test usage recorded successfully!
ğŸ“ Invalidating OLQ dashboard cache...
âœ… Dashboard cache invalidated!
```

**Worker Execution**:
```
adb logcat | grep "AnalysisWorker"
ğŸ”„ Starting TAT analysis for submission: abc123
   Step 1: TAT submission found with 12 stories
   Step 2: Status updated to ANALYZING
   Step 3: Generated TAT analysis prompt
   Step 4: AI analysis complete - received 15/15 OLQ scores
   Step 5: Submission updated with OLQ result
âœ… Push notification sent successfully!
ğŸ‰ TAT analysis completed successfully in 8432ms
```

**Dashboard Loading**:
```
adb logcat | grep "GetOLQDashboard"
ğŸ“ Fetching dashboard for user: userId123
âœ… Cache hit - returning cached data (load time: 45ms)
OR
âŒ Cache miss - fetching from Firestore (load time: 1203ms)
```

### File Locations Quick Reference

**ViewModels**:
- OIR: `app/ui/tests/oir/OIRTestViewModel.kt`
- PPDT: `app/ui/tests/ppdt/PPDTTestViewModel.kt`
- TAT: `app/ui/tests/tat/TATTestViewModel.kt`
- WAT: `app/ui/tests/wat/WATTestViewModel.kt`
- SRT: `app/ui/tests/srt/SRTTestViewModel.kt`
- SDT: `app/ui/tests/sdt/SDTTestViewModel.kt`
- GD: `app/ui/tests/gto/gd/GDTestViewModel.kt`
- GPE: `app/ui/tests/gpe/GPETestViewModel.kt`
- Lecturette: `app/ui/tests/gto/lecturette/LecturetteTestViewModel.kt`
- Interview: `app/ui/interview/session/InterviewSessionViewModel.kt`

**Workers**:
- PPDT: `app/workers/PPDTAnalysisWorker.kt`
- TAT: `app/workers/TATAnalysisWorker.kt`
- WAT: `app/workers/WATAnalysisWorker.kt`
- SRT: `app/workers/SRTAnalysisWorker.kt`
- SDT: `app/workers/SDTAnalysisWorker.kt`
- GTO: `app/workers/GTOAnalysisWorker.kt`
- Interview: `app/workers/InterviewAnalysisWorker.kt`

**Repositories**:
- Psych Tests: `core/data/remote/PsychTestSubmissionRepository.kt`
- GTO: `core/data/repository/FirestoreGTORepository.kt`
- Interview: `core/data/repository/FirestoreInterviewRepository.kt`
- OIR: `core/data/repository/FirestoreSubmissionRepository.kt`

**Dashboard**:
- Use Case: `core/domain/usecase/dashboard/GetOLQDashboardUseCase.kt`
- UI Card: `app/ui/home/student/components/OLQDashboardCard.kt`

**Prompts**:
- Psychology: `core/data/ai/prompts/PsychologyTestPrompts.kt`
- GTO: `core/data/ai/prompts/GTOTestPrompts.kt`
- Interview: `core/data/ai/prompts/SSBInterviewPrompts.kt`

---

## Key Architectural Patterns

### 1. ID-Based Navigation
All tests pass only `submissionId` (String) between screens, never complex objects.
Result screens fetch data via ViewModel using the ID.

### 2. StateFlow Updates
Always use `.update { it.copy(...) }` pattern for thread safety.
Never use `.value = _state.value.copy(...)` (race condition).

### 3. Worker Pattern
All background AI analysis uses WorkManager with:
- Network constraint
- Retry logic (3 attempts)
- Exponential backoff
- Fill missing OLQs with neutral score (6)

### 4. Cache Management
Dashboard uses 5-minute in-memory cache.
Invalidated after every test submission.
Force refresh via pull-to-refresh.

### 5. Error Handling
- Domain layer: `Result<T>` only
- Data/Presentation: `ErrorLogger.log()`
- User messages: String resources (`R.string.*`)

### 6. Firestore Split Architecture
- Submissions: Raw responses
- Results: OLQ analysis (separate collection)
- Security: Both require userId field

---

**Document Version**: 1.0  
**Last Verified**: December 23, 2025  
**Status**: All 10 tests operational with unified OLQ scoring
